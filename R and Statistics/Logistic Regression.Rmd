---
title: "Logistic Regression"
output:
  rmarkdown::html_document:
    theme: lumen
    toc: true
    toc_float: true
date: "2023-08-25"
---
13.1 Background
Logistic Regression

Let y be a binary categorical response variable:

  y={1 if event happens0 if event doesn't happen
      0 if event doesn't happen

Further define

  p= probability event happens
  1−p= probability event doesn't happen
  odds= odds event happens=p1−p

Then a logistic regression model of y by x is 
  log(odds)=β0+β1x

We can transform this to get (curved) models of odds and probability:

odds=eβ0+β1x
p=oddsodds+1=eβ0+β1xeβ0+β1x+1



Coefficient interpretation

  β0= LOG(ODDS) when x=0
  eβ0= ODDS when x=0
  β1= unit change in LOG(ODDS) per 1 unit increase in x
  eβ1= multiplicative change in ODDS per 1 unit increase in x

Generalized Linear Models

Logistic regression and (ordinary) linear regression are both special cases of the broader set of “generalized linear models”. In general, all generalized linear models assume that the model trend, i.e. the expected value of the response E(Y), can be “linked” to a linear combination of predictors via some link function g():

  g(E(Y))=Xβ
  E(Y)=g−1(Xβ)

In the case of ordinary linear regression, g() is the identity function:

  Y∼N(Xβ,σ2) with E(Y)=Xβ

In the case of logistic regression, g() is the logit function:

  Y∼Bern(p) with log(E(Y)1−E(Y))=log(p1−p)=Xβ
  
13.2 Exercises
13.2.1 Build, interpret, predict

Data story
The climbers_sub data is sub-sample of the Himalayan Database distributed through the R for Data Science TidyTuesday project. This dataset includes information on the results and conditions for various Himalayan climbing expeditions. Each row corresponds to a single member of a climbing expedition team:
```{r}
# NOTE: We turn success, our response variable, into a factor
climbers_sub <- read.csv("https://raw.githubusercontent.com/ajohns24/data/main/climbers_sub.csv") %>% 
  select(peak_name, success, age, oxygen_used, height_metres) %>% 
  mutate(success = as.factor(success))

head(climbers_sub)
```
Our goal will be to model whether or not a climber has success by their age. Since success is a binary categorical variable (a climber is either successful or they’re not), we’ll utilize logistic regression.

1. success vs age
Our goal is to understand how success (categorical) depends upon age (quantitative). Unfortunately, side-by-side plots of age vs success don’t help. For example, this plot indicates that successful climbers tend to be slightly younger, not whether younger climbers are more successful:
```{r}
ggplot(climbers_sub, aes(x = age, fill = success)) + 
  geom_density(alpha = 0.5)
```
Since we have a large data set and multiple (though sometimes not many) observations at each age, we can get a better picture by calculating the observed success rate at each age.
```{r}
# For each age, calculate 3 quantities and store the result as success_by_age
# n = number of climbers
# nsuccess = number of successful climbers
# success_rate
```
```{r}
# Now plot success rate by age
```
Since there are only a few data points at some ages, the above plot could be a bit misleading. Instead, plot the success rate of climbers in larger, more stable age brackets. NOTE: cut(age, breaks = 20) would cut age into 20 brackets.
```{r}
# Plot success rate by age
```

2. Logistic regression using tidymodels
To model the relationship between success and age, we can construct the logistic regression model.
```{r}
# STEP 1: Specify the modeling method
# For logistic regression we use the glm, not lm, engine
# and specify that this is a classification, not regression, task
logistic_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# STEP 2: estimate the model
climb_model_1 <- logistic_spec %>% 
  fit(success ~ age, data = climbers_sub)

# Get the model summary
climb_model_1 %>% 
  tidy()
```
Convince yourself that the model formulas on the log(odds), odds, and probability scales are as follows:

  log(odds of success) = 0.426 - 0.024age

  odds of success = e^(0.426 - 0.024age)

  probability of success = e^(0.426 - 0.024age) / (e^(0.426 - 0.024age) + 1)

3. Plotting the model
We now have the same model of success by age, but on 3 different scales. Construct and comment on the plots below – what do they indicate about the relationship between climber success and age?
```{r}
# Incorporate predictions on the probability, odds, & log-odds scales
climbers_predictions <- climb_model_1 %>% 
  augment(new_data = climbers_sub) %>% 
  rename(probability = .pred_TRUE) %>% 
  mutate(odds = probability / (1-probability)) %>% 
  mutate(log_odds = log(odds)) %>% 
  select(age, success, probability, odds, log_odds)

head(climbers_predictions)
```
```{r}
# Plot the model on 3 scales
ggplot(climbers_predictions, aes(x = age, y = log_odds)) + 
  geom_smooth(se = FALSE)
```
```{r}
ggplot(climbers_predictions, aes(x = age, y = odds)) + 
  geom_smooth(se = FALSE) 
```
```{r}
ggplot(climbers_predictions, aes(x = age, y = probability)) + 
  geom_smooth(se = FALSE) 
```

4. Predictions
Let’s use the model to predict the chance of success for a 20-year-old climber. Make sure these match up with your model plots. For reference:

  log(odds of success) = 0.426 - 0.024age
```{r}
# Predict the log(odds) of success



# Predict the odds of success



# Predict the probability of success
```
Now check your probability prediction:
```{r}
climb_model_1 %>% 
  predict(new_data = data.frame(age = 20), type = "prob")
```

5. Interpreting coefficients on the log(odds) scale
For reference: log(odds of success) = 0.426 - 0.024age
```{r}
ggplot(climbers_predictions, aes(x = age, y = log_odds)) + 
  geom_smooth(se = FALSE)
```
a) Interpret the intercept coefficient on the log(odds) scale.

b) Interpret the age coefficient on the log(odds) scale.

6. Interpreting coefficients on the log(oods) scale
For reference: odds of success = exp(0.426 - 0.024age)
```{r}
ggplot(climbers_predictions, aes(x = age, y = odds)) + 
  geom_smooth(se = FALSE)
```
a) Interpret the intercept coefficient on the odds scale.

b) Interpret the age coefficient on the odds scale. NOTE: If the age coefficient on the log(odds) scale is b, then e^b is the MULTIPLICATIVE change in the ODDS of success per 1 year increase in age. Or e^(10b) is the multiplicative change per 10 year increase in age.

7. Conclusions
What can we conclude about the the association between climbing success and age? Is it statistically discernible? Practically meaningful?


Details: Building and evaluating a logistic regression model

In ordinary linear regression, the residuals are key to building the model (via least squares) and to measuring the strength and quality of predictions (via R-squared and MAE). But the concept of a “residual” doesn’t make sense in logistic regression. Each climber is successful or not, y∈{0,1}, yet our predictions are on the probability scale.


Building the model: calculating coefficient estimates

A common strategy is to use iterative processes to identify coefficient estimates ^β that maximize the likelihood function

L(^β)= n∏i = 1pyii(1−pi)1−yi where log(pi1−pi)=xTi^β


Measuring model quality

We can evaluate logistic models relative to their ability to classify cases into binary categories using CV, sensitivity, & specificity (which we’ll do below).

8. success vs oxygen use
Next, let’s explore the relationship between success and oxygen_used.

a) Plot this relationship. HINT: First plot oxygen_used alone, and then modify it.

b) Construct a logistic regression model of success by oxygen_used. Store this as climb_model_2.

c) How can we interpret the intercept coefficient on the odds scale?
```{r}
exp(-1.33)
```

    The odds of success for people that use oxygen are roughly 0.26.
    The odds of success for people that don’t use oxygen are roughly 0.26.
    The odds of success for people that use oxygen are roughly one quarter (26%) as big as the odds of success for people that don’t use oxygen.

d) How can we interpret the oxygen_usedTRUE coefficient on the odds scale?
```{r}
exp(2.90)
```

    The odds of success for people that use oxygen are roughly 18.
    The odds of success for people that don’t use oxygen are roughly 18.
    The odds of success for people that use oxygen are roughly 18 times greater than the odds of success for people that don’t use oxygen.

9. success vs oxygen use and age
a) Construct and obtain a summary table for a model of success by age and oxygen_used. Store your model as climb_model_3.

b) Challenge: Plot this model on the probability scale.

c) Optional practice: Interpret the 2 non-intercept coefficients on the odds scale. Don’t forget to “control for…”!

13.2.2 Classify and evaluate
Next, we’ll explore how to us our models to classify whether or not a climber will be successful, and evaluate which model gives us the best classifications.

10. Classification
a) Using climb_model_3, predict the probability of success for a 20-year-old climber that uses oxygen.

b) Suppose you had to translate your probability prediction into a yes / no prediction. Yes or no: do you predict that a climber who uses oxygen will be successful? 

c) What “rule” are you using here? Mainly, to what threshold did you compare your probability to determine your yes/no classification? 

d) As we discussed, we can’t measure the accuracy of such a prediction by a residual. Our prediction is either right or wrong. For example, suppose that a certain 20-year-old climber used oxygen but failed to summit their peak. Was your prediction from part b right or wrong?

Using logistic regression for classification

For a new case with predictors x, we can use the logistic regression model to classify y:

    If probability >= c, then classify y as 1.
    If probability < c, then classify y as 0.

The quality of these classifications depends upon our choice of cut-off parameter c and provides a measure of the model quality itself.

11. Model evaluation - sensitivity, specificity, and overall accuracy
Next, let’s evaluate how well climb_model_3 classifies the climbers in our data set.
```{r}
# The classifications for each climber are stored as .pred_class
climb_model_3 %>% 
  augment(new_data = climbers_sub) %>% 
  head()
```
We can then compare these classifications to the actual climbing outcomes, and summarize the results in a confusion matrix. The rows here represent the actual outcomes, and the columns represent the classifications:
```{r}
# Confusion matrix
library(tidyr)
climb_model_3 %>% 
  augment(new_data = climbers_sub) %>% 
  count(success, .pred_class) %>% 
  pivot_wider(names_from = .pred_class, values_from = n)
```
a) We can use the confusion matrix to calculate 3 important metrics. First, show that this model has an overall accuracy rate of 80.2%. That is, it correctly predicted the outcome of 80.2% of all climbers.

b) Second, show that this model has a sensitivity, or true positive rate, of 61.7%. That is, it correctly predicted success for only 61.7% of the successful climbers.

c) Finally, show that this model has a specificity, or true negative rate, of 91.9%. That is, it correctly predicted unsuccessful outcomes for 91.9% of the unsuccessful climbers.

12. Changing the threshold
The above model quality metrics are based on our use of a 0.5 probability cut-off. We don’t have to.

a) Suppose that we wanted to increase the sensitivity of our model to 80%. What probability cut-off would work?

b) Using this same probability cut-off, what’s the new specificity of our model? Thus what’s the trade-off in increasing sensitivity?

c) Deciding which threshold to use depends upon the consequences of our classification errors. In the context of this climbing example, what do you think is more important, high sensitivity or high specificity?

13. sensitivity vs specificity
For the following scenarios, which is more important: increased sensitivity or increased specificity? What factors are you considering in your answer?

a) Classify a room as having carbon monoxide (y = 1) or not (y = 0).

b) Classify an email as spam (y = 1) or not spam (y = 0).

c) Classify a person as having a certain virus (y = 1) or not (y = 0).

14. Model comparison
We’ve now considered 3 models of climbing success. As we did for the third model, we can calculate accuracy metrics for the first 2 models:

model 	predictors 	overall 	sensitivity 	specificity
1 	    age 	        0.611 	0.000 	        0.999
2 	    oxygen_used 	0.802 	0.617 	        0.919
3 	    oxygen_used,age0.802 	0.617 	        0.919


a) Which model(s) had the highest overall accuracy?

b) Which model(s) were the best at predicting when a climber would not succeed, i.e. have the highest specificity?

c) Note that the evaluation metrics are the same for climb_model_2 and climb_model_3. What does this tell you?

d) Which of the 3 models is best? (There is a correct answer to this question!)
    
e) NOTE: We’re evaluating and comparing our models with the same data we used to build them. Just as with ordinary linear regression, we could but won’t cross-validate these metrics.

13.3 Solutions

5. At age 0 (doesn’t make sense), the typical log(odds of success) is 0.426. For every 1 year increase in age, log(odds of success) decrease by 0.024.

6. At age 0 (doesn’t make sense), the typical odds of success are 1.63. For every 1 year increase in age, odds of success are 97.6% as high.

12. Changing the threshold
a) Trial and error. You will need a cut-off lower than 0.5.
b) specificity decreases as sensitivity increases
c) probably specificity. the consequence of mistakenly predicting that someone will succeed might put climbers in danger.

13. sensitivity vs specificity
answers will vary

14. Model comparison
a) 2 and 3
b) 1
c) if we already have info about oxygen use, age isn’t a useful predictor
d) it’s more accurate than model 1 and simpler than model 3
